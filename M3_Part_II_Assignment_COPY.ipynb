{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "\n",
        "Part-of-Speech tagging, also known as POS tagging, is the process of assigning grammatical tags or labels to words in a sentence. The tags represent the syntactic category or part of speech of each word, such as noun, verb, adjective, adverb, etc. POS tagging is an essential step in many Natural Language Processing (NLP) tasks, including parsing, machine translation, and information retrieval.\n",
        "\n",
        "POS tagging can be approached using different techniques, including rule-based approaches, statistical approaches, and hybrid approaches that combine both. In statistical approaches, Hidden Markov Models (HMMs) and Maximum Entropy Markov Models (MEMMs) are commonly used.\n",
        "\n",
        "Implement a rule-based part-of-speech (POS) tagger:\n",
        "* a. Write a set of rules to assign POS tags to words based on their context\n",
        "* b. Apply the rules to a sample text and evaluate the accuracy of the tagger.\n",
        "\n",
        "\n",
        "\n",
        "Implement a statistical POS tagger using a pre-trained model:\n",
        "\n",
        "\n",
        "* a. Train a statistical POS tagger on a labeled corpus using a machine learning algorithm such as Naive Bayes or Maximum Entropy.\n",
        "* b. Apply the trained model to tag a sample text and evaluate its accuracy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Q05trEvPpQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker') #The maxent_ne_chunker contains two pre-trained English named entity chunkers trained on an ACE corpus (perhaps ACE ACE 2004 Multilingual Training Corpus?)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ2RhiyPSCv6",
        "outputId": "3ae0a238-086d-49c4-aea8-531019715ec3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gXSDBSDaPY12"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger #important for POS tagging\n",
        "\n",
        "\n",
        "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "\n",
        "# Rule-based POS Tagger\n",
        "def rule_based_pos_tagger(sentence):\n",
        "    # Define your rules here\n",
        "    rules = [\n",
        "          (re.compile(r'\\bThe\\b'), 'DT'),\n",
        "          (re.compile(r'\\bcat\\b'), 'NN'),\n",
        "          (re.compile(r'\\bis\\b'), 'VB'),\n",
        "          (re.compile(r'\\bsitting\\b'), 'VB'),\n",
        "          (re.compile(r'\\bon\\b'), 'IN'),\n",
        "          (re.compile(r'\\bthe\\b'), 'DT'),\n",
        "          (re.compile(r'\\bmat\\b'), 'NN'),\n",
        "      ]\n",
        "    tagged_sentence = []\n",
        "    words = word_tokenize(sentence)\n",
        "    for word in words:\n",
        "        for pattern, tag in rules:\n",
        "            if pattern.match(word):\n",
        "                tagged_sentence.append((word, tag))\n",
        "                break\n",
        "        else:\n",
        "            tagged_sentence.append((word, 'UNKNOWN'))\n",
        "    return tagged_sentence\n",
        "\n",
        "# Statistical POS Tagger\n",
        "def statistical_pos_tagger(sentence):\n",
        "    # Train your model on a labeled corpus (e.g., treebank)\n",
        "    train_data = treebank.tagged_sents()[:3000]\n",
        "    # Train your statistical model here\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    train_size = int(len(train_data) * 0.8)\n",
        "    train_set = train_data[:train_size]\n",
        "    test_set = train_data[train_size:]\n",
        "\n",
        "    # Create taggers\n",
        "    default_tagger = DefaultTagger('NN')  # Default tagger assigns 'NN' to all words\n",
        "    unigram_tagger = UnigramTagger(train_set, backoff=default_tagger)  # Unigram tagger using training set\n",
        "    bigram_tagger = BigramTagger(train_set, backoff=unigram_tagger)  # Bigram tagger using training set and fallback to unigram tagger\n",
        "\n",
        "    # Evaluate on test set\n",
        "    accuracy = bigram_tagger.accuracy(test_set)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "    # Apply the trained model to tag the sentence\n",
        "    tagged_sentence  = bigram_tagger.tag(word_tokenize(sentence))\n",
        "    #tagged_sentence = nltk.pos_tag(words)\n",
        "    #tagged_sentence.append(tagged_sentence)\n",
        "    return tagged_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "sample_sentence = \"The cat is sitting on the mat.\"\n",
        "\n",
        "# Rule-based POS Tagging\n",
        "rule_based_tags = rule_based_pos_tagger(sample_sentence)\n",
        "print(\"Rule-based POS Tags:\")\n",
        "print(rule_based_tags)\n",
        "\n",
        "# Statistical POS Tagging\n",
        "statistical_tags = statistical_pos_tagger(sample_sentence)\n",
        "print(\"Statistical POS Tags:\")\n",
        "print(statistical_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exUD_vjjR6T7",
        "outputId": "8d7a9ec6-a444-416f-e368-f3639e430802"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based POS Tags:\n",
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VB'), ('sitting', 'VB'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', 'UNKNOWN')]\n",
            "Accuracy: 0.8748033560566335\n",
            "Statistical POS Tags:\n",
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, NLTK has a built in function call ```pos_tags``\n",
        "See example below"
      ],
      "metadata": {
        "id": "zoASyaNWdgYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"The cat is sitting on the mat.\"\n",
        "\n",
        "tagged_sentence = nltk.pos_tag(word_tokenize(sample_sentence))\n",
        "print(tagged_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYSqHPf4dpMS",
        "outputId": "c6505efc-fba7-4bf6-f572-04bc973d85bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Exercise\n",
        "\n",
        "Update the Rule-based tagger with patterns using regex. An example could be:\n",
        "\n",
        "\n",
        "\n",
        "      ```  (r'\\b\\w+s\\b|\\b\\w+es\\b', 'NN'),     # Nouns ending ```\n",
        "\n",
        "  From here proivde an updated rule-based tagger and statistical based tagger that can apply a part of speech tag for the following complex sentence:\n",
        "\n",
        "  ```\n",
        "  sentence = \"The quick brown fox jumps over the lazy dog while it's raining heavily.\"\n",
        "\n",
        "  ```"
      ],
      "metadata": {
        "id": "S9jgjuE4euOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "\n",
        "# Rule-based POS Tagger\n",
        "def rule_based_pos_tagger(sentence):\n",
        "    rules = [\n",
        "        (re.compile(r'\\bThe\\b', re.IGNORECASE), 'DT'),  # Determiner\n",
        "        (re.compile(r'\\bquick\\b', re.IGNORECASE), 'JJ'),  # Adjective\n",
        "        (re.compile(r'\\bbrown\\b', re.IGNORECASE), 'JJ'),  # Adjective\n",
        "        (re.compile(r'\\bfox\\b', re.IGNORECASE), 'NN'),  # Noun\n",
        "        (re.compile(r'\\bjumps\\b', re.IGNORECASE), 'VB'),  # Verb\n",
        "        (re.compile(r'\\bover\\b', re.IGNORECASE), 'IN'),  # Preposition\n",
        "        (re.compile(r'\\blazy\\b', re.IGNORECASE), 'JJ'),  # Adjective\n",
        "        (re.compile(r'\\bdog\\b', re.IGNORECASE), 'NN'),  # Noun\n",
        "        (re.compile(r'\\bwhile\\b', re.IGNORECASE), 'IN'),  # Conjunction\n",
        "        (re.compile(r'\\bit\\'s\\b', re.IGNORECASE), 'PRP'),  # Pronoun\n",
        "        (re.compile(r'\\braining\\b', re.IGNORECASE), 'VB'),  # Verb\n",
        "        (re.compile(r'\\bheavily\\b', re.IGNORECASE), 'RB'),  # Adverb\n",
        "        (re.compile(r'\\b\\w+s\\b|\\b\\w+es\\b', re.IGNORECASE), 'NNS'),  # Plural nouns\n",
        "    ]\n",
        "    tagged_sentence = []\n",
        "    words = word_tokenize(sentence)\n",
        "    for word in words:\n",
        "        for pattern, tag in rules:\n",
        "            if pattern.match(word):\n",
        "                tagged_sentence.append((word, tag))\n",
        "                break\n",
        "        else:\n",
        "            tagged_sentence.append((word, 'UNKNOWN'))\n",
        "    return tagged_sentence\n",
        "\n",
        "# Statistical POS Tagger\n",
        "def statistical_pos_tagger(sentence):\n",
        "    train_data = treebank.tagged_sents()[:3000]\n",
        "\n",
        "    # Train and Test split\n",
        "    train_size = int(len(train_data) * 0.8)\n",
        "    train_set = train_data[:train_size]\n",
        "    test_set = train_data[train_size:]\n",
        "\n",
        "    # Create taggers\n",
        "    default_tagger = DefaultTagger('NN')\n",
        "    unigram_tagger = UnigramTagger(train_set, backoff=default_tagger)\n",
        "    bigram_tagger = BigramTagger(train_set, backoff=unigram_tagger)\n",
        "\n",
        "    # Model Evaluation\n",
        "    accuracy = bigram_tagger.accuracy(test_set)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Apply the trained model to tag the sentence\n",
        "    tagged_sentence = bigram_tagger.tag(word_tokenize(sentence))\n",
        "    return tagged_sentence"
      ],
      "metadata": {
        "id": "zsFIKF3QetPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691be743-35a3-4243-af69-2e743235341d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show printed output below\n",
        "sentence = \"The quick brown fox jumps over the lazy dog while it's raining heavily.\"\n",
        "\"\"\"your POS tagging function\"\"\"\n",
        "\n",
        "# Rule-based POS Tagging\n",
        "rule_based_tags = rule_based_pos_tagger(sentence)\n",
        "print(\"Rule-based POS Tags:\")\n",
        "print(rule_based_tags)\n",
        "\n",
        "# Statistical POS Tagging\n",
        "statistical_tags = statistical_pos_tagger(sentence)\n",
        "print(\"Statistical POS Tags:\")\n",
        "print(statistical_tags)\n",
        "\n",
        "# NLTK's built-in POS Tagging\n",
        "tagged_sentence = nltk.pos_tag(word_tokenize(sentence))\n",
        "print(\"NLTK's built-in POS Tags:\")\n",
        "print(tagged_sentence)"
      ],
      "metadata": {
        "id": "v3qmcVF6hxrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a1a05e-8509-4b17-a64d-4e8cb53bfa63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumps', 'VB'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'UNKNOWN'), (\"'s\", 'UNKNOWN'), ('raining', 'VB'), ('heavily', 'RB'), ('.', 'UNKNOWN')]\n",
            "Accuracy: 0.8748033560566335\n",
            "Statistical POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NN'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'NN'), ('heavily', 'RB'), ('.', '.')]\n",
            "NLTK's built-in POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'VBG'), ('heavily', 'RB'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Hidden Markov Models (HMM) for POS Tagging\n",
        "A Hidden Markov Model (HMM) is a statistical model that is widely used in various applications, including Natural Language Processing (NLP). An HMM is a type of generative model that incorporates hidden states and observable outputs. It assumes that there is an underlying sequence of hidden states that generates a sequence of observable outputs.\n",
        "\n",
        "In the context of NLP, HMMs are often used for tasks such as part-of-speech tagging, where the hidden states represent the part-of-speech tags and the observable outputs are the words in a sentence. HMMs are particularly suitable for such sequential data modeling tasks.\n",
        "\n",
        "The book \"Speech and Language Processing\" by Jurafsky and Martin provides a comprehensive explanation of HMMs in Chapter 8, including the underlying mathematical concepts, the training algorithms, and applications in NLP. The chapter also covers various extensions and improvements to the basic HMM model, such as the use of different probability distributions and more sophisticated inference techniques.\n",
        "\n",
        "Let's break down the components of an HMM:\n",
        "\n",
        "* Hidden States: The hidden states in an HMM represent the latent variables that generate the observable outputs. For example, in part-of-speech tagging, the hidden states correspond to the different parts of speech (nouns, verbs, adjectives, etc.). The set of possible hidden states is denoted as S.\n",
        "\n",
        "* Observable Outputs: The observable outputs, also known as emissions, are the data or measurements that are observed. In part-of-speech tagging, the observable outputs correspond to the words in a sentence. The set of possible observable outputs is denoted as V.\n",
        "\n",
        "* Transition Probabilities: The transition probabilities model the probabilities of transitioning from one hidden state to another. These probabilities capture the underlying dynamics of the system. In part-of-speech tagging, the transition probabilities represent the likelihood of transitioning from one part of speech to another. The transition probabilities are denoted as A, where A(i, j) represents the probability of transitioning from state i to state j.\n",
        "\n",
        "* Emission Probabilities: The emission probabilities represent the probabilities of observing a specific output given a hidden state. In part-of-speech tagging, the emission probabilities capture the likelihood of observing a word given a particular part of speech. The emission probabilities are denoted as B, where B(j, k) represents the probability of emitting output k from state j.\n",
        "\n",
        "\n",
        "Implement an HMM-based POS tagger:\n",
        "\n",
        "* a. Train an HMM model on a labeled corpus to learn the  transition and emission probabilities.\n",
        "* b. Use the Viterbi algorithm to decode the most probable sequence of tags for a given sentence.\n",
        "* c. Apply the HMM tagger to a sample text and evaluate its accuracy."
      ],
      "metadata": {
        "id": "uyibrYW-PyKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.tag import hmm\n",
        "\n",
        "\n",
        "# HMM POS Tagger\n",
        "def hmm_pos_tagger(sentence):\n",
        "    train_data = treebank.tagged_sents()\n",
        "    test_data = treebank.tagged_sents()[3000:]\n",
        "\n",
        "    # Train HMM Tagger with smoothing\n",
        "    trainer = nltk.tag.hmm.HiddenMarkovModelTrainer()\n",
        "    hmm_tagger = trainer.train(train_data)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = hmm_tagger.evaluate(test_data)\n",
        "    print(\"HMM Tagger Accuracy:\", accuracy)\n",
        "\n",
        "    # Apply the trained model to tag the sentence\n",
        "    tagged_sentence = hmm_tagger.tag(word_tokenize(sentence))\n",
        "    return tagged_sentence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vzn3YRZsQcpY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HMM POS Tagging\n",
        "hmm_tags = hmm_pos_tagger(sample_sentence)\n",
        "print(\"HMM POS Tags:\")\n",
        "print(hmm_tags)\n"
      ],
      "metadata": {
        "id": "ltEUcahYUV88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90305ac-19a0-41ff-fa03-93d2334481d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-4c54355029fc>:15: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = hmm_tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMM Tagger Accuracy: 0.9838981221670624\n",
            "HMM POS Tags:\n",
            "[('Barack', 'NNP'), ('Obama', 'NNP'), ('was', 'NNP'), ('born', 'NNP'), ('in', 'NNP'), ('Hawaii', 'NNP'), ('.', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Named Entity Recognition (NER) Methods and Evaluation\n",
        "\n",
        "Implement a rule-based NER system:\n",
        "a. Define a set of rules to identify named entities (e.g., person names, locations, organizations) in a text.\n",
        "b. Apply the rules to a sample text and evaluate the precision, recall, and F1-score of the NER system.\n",
        "\n",
        "Implement a statistical NER system using a pre-trained model:\n",
        "* a. Train a statistical NER model on a labeled corpus using machine learning techniques like Conditional Random Fields (CRF) or Support Vector Machines (SVM).\n",
        "* b. Apply the trained model to identify named entities in a sample text and evaluate its performance using precision, recall, and F1-score.\n",
        "\n",
        "Compare the performance of rule-based and statistical NER systems:\n",
        "* a. Apply both the rule-based and statistical NER systems to the same sample text.\n",
        "* b. Compare their precision, recall, and F1-score to analyze their strengths and weaknesses.\n",
        "\n",
        "Note: For evaluating the taggers and NER systems, you can use labeled datasets available in NLTK or other sources. You should report metrics such as accuracy, precision, recall, and F1-score for a comprehensive analysis of the implemented approaches."
      ],
      "metadata": {
        "id": "Ddk7unNBQdCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.chunk import ne_chunk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "# Rule-based NER\n",
        "def rule_based_ner(sentence):\n",
        "    # Apply your rule-based NER here\n",
        "    tagged_sentence = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
        "    return tagged_sentence\n",
        "\n",
        "# Statistical NER\n",
        "def statistical_ner(sentence):\n",
        "    # For simplicity, we'll use NLTK's pre-trained named entity chunker\n",
        "    tagged_sentence = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
        "    return tagged_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "MKO6bnu8QnmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f70725-25ed-4c90-8b99-6d5bc10d3460"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"Barack Obama was born in Hawaii.\"\n",
        "\n",
        "# Rule-based NER\n",
        "rule_based_ner_tags = rule_based_ner(sample_sentence)\n",
        "print(\"Rule-based NER Tags:\")\n",
        "print(rule_based_ner_tags)\n",
        "\n",
        "# Statistical NER\n",
        "statistical_ner_tags = statistical_ner(sample_sentence)\n",
        "print(\"Statistical NER Tags:\")\n",
        "print(statistical_ner_tags)\n"
      ],
      "metadata": {
        "id": "E5zgLyuFUcVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f2211a-6c04-4bd9-9c26-8f0fd3ff44f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based NER Tags:\n",
            "(S\n",
            "  (PERSON Barack/NNP)\n",
            "  (PERSON Obama/NNP)\n",
            "  was/VBD\n",
            "  born/VBN\n",
            "  in/IN\n",
            "  (GPE Hawaii/NNP)\n",
            "  ./.)\n",
            "Statistical NER Tags:\n",
            "(S\n",
            "  (PERSON Barack/NNP)\n",
            "  (PERSON Obama/NNP)\n",
            "  was/VBD\n",
            "  born/VBN\n",
            "  in/IN\n",
            "  (GPE Hawaii/NNP)\n",
            "  ./.)\n"
          ]
        }
      ]
    }
  ]
}